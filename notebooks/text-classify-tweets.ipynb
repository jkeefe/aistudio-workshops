{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2FtGCN6bVsg"
   },
   "source": [
    "# Finding Fact-checkable Tweets with Machine Learning\n",
    "\n",
    "This notebook was copied and modified from one originally created by Jeremy Howard and the other folks at [fast.ai](https://fast.ai) as part of [this fantastic class](https://course.fast.ai/). Specifically, it comes from Lesson 4. You can [see the lession video](https://course.fast.ai/videos/?lesson=4) and [the original class notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb). \n",
    "\n",
    "For more information about this project, and details about how to use this work in the wild, check out our [Quartz AI Studio blog post about the checkable-tweets project](https://qz.ai/?p=89).\n",
    "\n",
    "-- John Keefe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using this notebook\n",
    "\n",
    "Essentially you need a computer that's running a GPU running fast.ai. There are a few ways to do this without owning a computer with a GPU (I certainly don't). There are [lots of options](https://course.fast.ai/index.html). I like to use use [the Amazon EC2 setup](https://course.fast.ai/start_aws.html), which is probably the most complicated. In most of these cases, you'll just clone [the workshop repository](https://github.com/Quartz/aistudio-workshops) and get the notebook running.\n",
    "\n",
    "I'm also tailoring this notebook for use with [Google Colaboratory](https://colab.research.google.com), which as of this writing is the fastest, cheapest (free) way to get going.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're using Google Colaboratory ...\n",
    "\n",
    "Be aware that Google Colab instances are ephemeral -- they vanish *Poof* when you close them, or after a period of sitting idle (currently 90 minutes).\n",
    "\n",
    "There are great steps on the fast.ai site for [getting started with fast.ai an Google Colab](https://course.fast.ai/start_colab.html). \n",
    "\n",
    "Those instructions will show you how to save your own copy of this _notebook_ to Google Drive.\n",
    "\n",
    "They also tell you how to save a copy of your _data_ to Google Drive (Step 4), which is unneccesary for this workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL GOOGLE COLAB USERS RUN THIS CELL\n",
    "\n",
    "## This runs a script that installs fast.ai\n",
    "!curl -s https://course.fast.ai/setup/colab | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are _not_ using Google Colaboratory ...\n",
    "\n",
    "Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NON-COLABORATORY USERS SHOULD RUN THIS CELL\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everybody do this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AND *EVERYBODY* SHOULD RUN THIS CELL\n",
    "\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-25 23:40:19--  https://qz-aistudio-public.s3.amazonaws.com/workshops/austin_tweet_data.zip\n",
      "Resolving qz-aistudio-public.s3.amazonaws.com (qz-aistudio-public.s3.amazonaws.com)... 52.216.161.19\n",
      "Connecting to qz-aistudio-public.s3.amazonaws.com (qz-aistudio-public.s3.amazonaws.com)|52.216.161.19|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 566805 (554K) [application/zip]\n",
      "Saving to: ‚Äòaustin_tweet_data.zip‚Äô\n",
      "\n",
      "austin_tweet_data.z 100%[===================>] 553.52K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2019-08-25 23:40:19 (51.8 MB/s) - ‚Äòaustin_tweet_data.zip‚Äô saved [566805/566805]\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://qz-aistudio-public.s3.amazonaws.com/workshops/austin_tweet_data.zip\n",
    "!unzip austin_tweet_data.zip > /dev/null\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_coded_austin_tweets.csv  tweet_corpus.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TPvnzypbVsq"
   },
   "source": [
    "### Take a peek at the tweet data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I21aOI9xbVsr"
   },
   "source": [
    "Working with Dan Keemahill and Madlin Mekelburg over a couple of weeks during the 2019 Texas state legislative session, I have have a set of 3,797 tweets humans at the Austin American-Statesman have determined are ‚Äì¬†or are not ‚Äì statements that can be fact-checked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kWwuVUg9QHo8",
    "outputId": "703590d9-71c2-4d1b-96cf-aa0a113be58a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>checkable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TOMORROW: Dallas Workers Head to TX Capitol to...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Texas House members told to stop secretly reco...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SB 1163 - Relating to establishing and funding...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Did you know that we‚Äôre carbon neutral* when i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Check our this article on the Baylor sexual as...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         tweet_text  checkable\n",
       "0           0  TOMORROW: Dallas Workers Head to TX Capitol to...      False\n",
       "1           1  Texas House members told to stop secretly reco...       True\n",
       "2           2  SB 1163 - Relating to establishing and funding...      False\n",
       "3           3  Did you know that we‚Äôre carbon neutral* when i...       True\n",
       "4           4  Check our this article on the Baylor sexual as...      False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I read the csv into a data frame I called `austin_tweets`\n",
    "# and take a look at the first few rows\n",
    "path = Path('./data')\n",
    "austin_tweets = pd.read_csv(path/'hand_coded_austin_tweets.csv')\n",
    "austin_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eym6ulq0bVuz"
   },
   "source": [
    "## Building the language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "62pxEwWPbVvI"
   },
   "source": [
    "Before we make a model that classifies whether tweets are checkable, we're going to build a model that 'understands' the rules of English ‚Äì the language model. \n",
    "\n",
    "Even several thousand tweets isn't enough to teach a computer patterns of English, so we'll start with a language model pretrained on a thousands of Wikipedia articles called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset). That language model has been trained to guess the next word in a sentence based on all the previous words. It has a recurrent structure with a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "We'll take that Wikitext model and fine-tune it for our particular dataset‚Äìthe #txlege tweets. Because the English of #txlege tweets isn't the same as the English of Wikipedia, we'll adjust the internal parameters of the model by a little bit. That includes adding words that might be extremely common in the tweets but would be barely present in wikipedia‚Äìand therefore might not be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FT0C6-vpbVvK"
   },
   "source": [
    "### Adding more tweets for the language model\n",
    "\n",
    "We'll use the text in the 3,797 tweets we already have to help the language model better \"understand\" our data set. To give it even more examples, I collected several days worth of (uncategorized) #txlege tweets, which are in a file called `tweet_corpus.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "18kBCGjhbVvQ",
    "outputId": "e36434d1-d47d-44c0-c6ab-82a61843ad2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State Rep. @CBellJr earned an F on this year's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#txlege https://t.co/1qqa0sFEnY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICYMI: @dallasnews editorial weighs in on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My life is complete! #txlege #FlagDay #mindblo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On June 14, 1777, our nation adopted the U.S. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text\n",
       "0  State Rep. @CBellJr earned an F on this year's...\n",
       "1                    #txlege https://t.co/1qqa0sFEnY\n",
       "2  ICYMI: @dallasnews editorial weighs in on the ...\n",
       "3  My life is complete! #txlege #FlagDay #mindblo...\n",
       "4  On June 14, 1777, our nation adopted the U.S. ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the corpus, which has one tweet per row,\n",
    "# and take a look at the first frew rows\n",
    "corpus_tweets = pd.read_csv(path/'tweet_corpus.txt')\n",
    "corpus_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aQyQIh_vNhrH",
    "outputId": "9a6afe30-01c4-4445-d7a7-8c835d7d62fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3797, 3688, 7485)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here I concatenate the two tweet sets\n",
    "lm_tweets = pd.concat([austin_tweets,corpus_tweets], sort=True)\n",
    "\n",
    "# as a sanity check, let's look at the size of each set, \n",
    "# and then the ontatenated set\n",
    "len(austin_tweets), len(corpus_tweets), len(lm_tweets),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g55U1v3mbVvm"
   },
   "source": [
    "Great: Now we have 7,485 tweets to use for the language model.\n",
    "\n",
    "One thing to note ... the first set had two columns, `checkable` and `tweet_text`, while the corpus had just one collumn,  `tweet_text`. The combined has the original two columns, though many of the entries will be `NaN` for \"not a number.\" Thats okay, because we're only going to use the `tweet_text` column for the language model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LPVLlF5sbVvn",
    "outputId": "5aba630c-8742-4147-b818-d4d32dff8e2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>checkable</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From our friends at @ProgressTX: One of the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@GregAbbott_TX The Texas House failed Texans. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Good to see one recommendation from Gov. Abbot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our executive director @antgutierrez spoke to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 checkable                                         tweet_text\n",
       "3683         NaN       NaN  From our friends at @ProgressTX: One of the to...\n",
       "3684         NaN       NaN  @GregAbbott_TX The Texas House failed Texans. ...\n",
       "3685         NaN       NaN  Good to see one recommendation from Gov. Abbot...\n",
       "3686         NaN       NaN  Our executive director @antgutierrez spoke to ...\n",
       "3687         NaN       NaN                                                NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the last few rows ... and we can see NaNs in the `checkable` column, \n",
    "# which is ok here because we don't use that column in the language model\n",
    "lm_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFp92p9NbVvs"
   },
   "outputs": [],
   "source": [
    "# But we can't have NaN in the 'tweet_text' column, because it will make things unhappy.\n",
    "# Let's fix that:\n",
    "lm_tweets.dropna(subset=['tweet_text'], inplace=True)\n",
    "\n",
    "# Saving as csv for easier reading in a moment\n",
    "lm_tweets.to_csv(path/'lm_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fU_R9lxbVv7"
   },
   "source": [
    "Fast.ai uses a concept called a \"[data bunch](https://docs.fast.ai/basic_data.html)\" to handle machine-learning data, which takes care of a lot of the more fickle machine-learning data preparation.\n",
    "\n",
    "We have to use a special kind of data bunch for the language model, one that ignores the labels, and will shuffle the texts at each epoch before concatenating them all together (only the training set gets shuffled; we don't shuffle for the validation set). It will also create batches that read the text in order with targets (aka the best guesses) that are the next word in the sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2rJuWVCbVv5"
   },
   "outputs": [],
   "source": [
    "# Loading in data with the TextLMDataBunch factory class, using all the defaults\n",
    "data_lm = TextLMDataBunch.from_csv(path, 'lm_tweets.csv', text_cols='tweet_text', label_cols='checkable')\n",
    "data_lm.save('data_lm_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pwB-RJOjOSG_"
   },
   "source": [
    "### Quick digression: Let's look at the data\n",
    "\n",
    "The data bunch function does some nifty things behind the scenes. Let's take a moment to look at what is happening. (This is optional, but interesting!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMqNHzHabVub"
   },
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLWA1H6VbVub"
   },
   "source": [
    "The first step of processing is to split the raw tweets into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but fast.ai is smarter:\n",
    "\n",
    "- we need to take care of punctuation\n",
    "- some words are contractions of two different words, like isn't or don't\n",
    "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
    "\n",
    "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "QwRe7uZ1bVu5",
    "outputId": "b49a87ff-818d-476c-df73-836a7153c5a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxmaj cornyn is a racist bigot who has dementia . xxmaj we are not in 1940s , commie xxmaj cornyn ! # txlege xxbos xxmaj true education is about relationships ... xxmaj simple way to ‚Äú test ‚Äù that ‚Äî &gt; üëç or üëé . # txed # txlege https : / / t.co / xxunk xxbos xxunk awards school districts in need with grants to help students achieve their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>our nation 's history - b / c it 's a terrible idea with no clearly defined rules # txlege xxbos @gregabbott_tx xxmaj likewise clearing xxunk rape tests can eliminate innocent men xxunk accused . xxmaj then the actual xxunk is run to ground and prosecuted . xxmaj thanks to # txlege for getting this dome . xxmaj and gov xxmaj abbott for signing , xxbos xxmaj nice to see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>with families against xxup sb 4 . # txlege xxbos 86th xxmaj leg xxmaj stats time . xxup xxunk xxmaj stat xxmaj rpt has xxunk bills passing , xxmaj leg xxmaj reference xxmaj library xxmaj rpt has xxunk , and xxmaj xxunk xxmaj stat xxmaj rpt has 1,184 . xxmaj all agree on xxunk bills filled . xxmaj my search has 1,184 . xxmaj so going with the 16 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>texas xxmaj house just passed xxup hb1936 from @reptonirosetx that restricts use of the death penalty for people with severe mental illness , instead giving them life in prison without xxunk . \\n \\n  xxmaj rose asks her colleagues to ‚Äú be pro - life from the womb to the tomb . ‚Äù # txlege xxbos @sarahforhd134 xxmaj way to go , congrats ! xxmaj the # xxunk will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>the face of renewed public opposition to xxmaj confederate monuments , several xxmaj southern states have passed laws making it extremely difficult to remove historical monuments . \\n \\n  https : / / t.co / oap0hd8sov # txlege xxbos xxmaj abigail xxmaj xxunk : xxmaj we 're in a data - driven age and we 've got to get serious about how we use that data to improve things</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note that language models can use a lot of GPU, here\n",
    "# If you're not using Google Colab you may need to decrease batch size\n",
    "bs=48\n",
    "data_lm = load_data(path, 'data_lm_tweets', bs=bs)\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAlddd1CbVug"
   },
   "source": [
    "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
    "- the \"'s\" are grouped together in one token\n",
    "- the contractions are separated like this: \"did\", \"n't\"\n",
    "- content has been cleaned for any HTML symbol and lower cased\n",
    "- there are several special tokens (all those that begin by xx), to replace unknown tokens (see below) or to introduce different text fields (here we only have one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pF6JV9osbVuh"
   },
   "source": [
    "#### Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nbllo71jbVui"
   },
   "source": [
    "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
    "\n",
    "The correspondance from ids to tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ub9Wpy0VbVui",
    "outputId": "9d86f928-8baf-4d26-86cb-9a230aa1b8de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '/']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dHeF4qzbVup"
   },
   "source": [
    "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rirfNAiLbVup",
    "outputId": "be6d8556-6076-45a6-af2f-10c3c663d62c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxunk # sarahfabianisamonster # sarahfabianisagarbageperson # trumptortureschildren # trumpconcentrationcamps # trumpisaracist xxmaj john xxmaj cornyn is a racist bigot who has dementia . xxmaj we are not in 1940s , commie xxmaj cornyn ! # txlege"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSYlLii3bVus"
   },
   "source": [
    "But the underlying data is all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pcaoh2nobVut",
    "outputId": "65463433-ce44-4b0a-e372-5a479096d824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    0,   10, 4165,   10, 4166,   10, 4167,   10, 2974])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.train_ds[1][0].data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbwXbu_6Tk7T"
   },
   "source": [
    "### Back to making the Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rY0LkJCQbVwF"
   },
   "source": [
    "We can then put all of our tweets (now stored in `data_lm`) in a learner object very easily with the Wikitext model loaded with the pretrained weights (here called `AWD_LTSM`). They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiiXrA6zbVwH"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfAXUyLnOB_J"
   },
   "source": [
    "One of the most important settings when we actually _train_ our model is the **learning rate**. I'm not going to dive into it here (though I encourage you to explore it), but will use a fast.ai tool to find the best learning rate to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W7b-Z94dbVwL",
    "outputId": "f6044993-11ab-4889-c0fe-892243e61a2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "Un204GpfbVwO",
    "outputId": "607fdc89-064b-427b-e92e-f35bdc868923"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "td3D3mK8TtHa"
   },
   "source": [
    "This gives us a graph of the optimal learning rate ... which is the point where the graph really dives downward (`1e-02`). Again, there's much more on picking and learning rates in the fast.ai course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BQA3dZWPachE"
   },
   "source": [
    "Now we can train the Language Model. (Essentailly, we're training it to be good at guessing the *next word* in a sentence, given all of the previous words.)\n",
    "\n",
    "The variabales we're passing are `1` to just do one cycle of learning, the learning rate of `1e-2`, and some momentum settings we won't get into here -- but these are pretty safe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "pveLnA6kbVwQ",
    "outputId": "38ef873c-5c2a-461d-9688-d8f4e1edbd5f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:25 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.211631</td>\n",
       "      <td>3.573457</td>\n",
       "      <td>0.369142</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "o-dYIVFcbVwS",
    "outputId": "aa2db805-6429-4592-f905-0479b9872820"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.981636</td>\n",
       "      <td>3.663427</td>\n",
       "      <td>0.369721</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-1, moms=(0.8,0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yMTSnTqIbVwU"
   },
   "outputs": [],
   "source": [
    "# optionally save and reload the model (file is about 150MB)\n",
    "learn.save('fit_head')\n",
    "learn.load('fit_head');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8kZOKSybVwX"
   },
   "source": [
    "To complete the fine-tuning, we \"unfreeze\" the original Wikitext language model and let the new training efforts -- work their way into the original neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "kTfuNCuhbVwX",
    "outputId": "1e99e6bc-8421-4d63-faf3-4c16fb3f07f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 02:07 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.420573</td>\n",
       "      <td>3.316068</td>\n",
       "      <td>0.400783</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.179419</td>\n",
       "      <td>3.185807</td>\n",
       "      <td>0.417638</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.848459</td>\n",
       "      <td>3.160211</td>\n",
       "      <td>0.423794</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.583529</td>\n",
       "      <td>3.180158</td>\n",
       "      <td>0.422932</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This takes a couple of minutes!\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xq3OgYK-bVwb"
   },
   "outputs": [],
   "source": [
    "# optionally save what we have - file is about 300MB\n",
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fv0mZuVhbVwd"
   },
   "source": [
    "While our accuracy may _seem_ low ... in this case it means the language model correctly guessed the next word in a sentence more than 1/3 of the time. That's pretty good! And we can see that even when it's wrong, it makes some pretty \"logical\" guesses. \n",
    "\n",
    "Let's give it a starting phrase and see how it does:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "_Wws03kmbVwd",
    "outputId": "dd545482-c5c8-4e93-a79e-64578e6478a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wonder if this is Texas ' # gun ban ? # txlege # txed https : / / t.co / Scheduling God xxbos If you already know who is serving ! we need to know where we are .\n",
      "I wonder if this bill happened in Texas or in the Woodlands , Texas , with a population of over 2.6 . # txlege xxbos Texas House \n",
      "  https : / / t.co / team xxbos Been a\n",
      "I wonder if this is the last time a Texas legislator has been arrested for using an auto - parts to improve school safety . # txlege xxbos Save # txlege companies & & property tax reform at # txlege all over\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"I wonder if this\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 3\n",
    "\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hj3aD0UebVwr"
   },
   "source": [
    "Remember, these are not real ... they were _generated_ by the model when it tried to guess each of the next words in the sentence! Generating text like this is not why we made the language model (though you can see where text-generation AI starts from!)\n",
    "\n",
    "Also note that the model is often crafting the response _in the form of a tweet!_\n",
    "\n",
    "We now save not only the model, but also its encoder, which is the mathematical representation of what the language model \"understands\" about English patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thkQAeQ2bVwr"
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zt6pDPEDbVww"
   },
   "source": [
    "## Building the classifier model\n",
    "\n",
    "This is the model that will use our langauge model **and** the hand-coded tweets to guess if new tweets are fact-checkable or not.\n",
    "\n",
    "We'll create a new data bunch that only grabs the hand-coded tweets and keeps track of the labels there (true or false, for fact-checkability). We also pass in the `vocab` -- which is the list of the most useful words from the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntIAhZbbbVw1"
   },
   "outputs": [],
   "source": [
    "data_clas = TextClasDataBunch.from_csv(path, 'hand_coded_austin_tweets.csv', vocab=data_lm.vocab, text_cols='tweet_text', label_cols='checkable')\n",
    "\n",
    "data_clas.save('data_clas_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3wfbjMrRDzf"
   },
   "source": [
    "And here's how the computer has tokenized the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "iBHYA4q_bVw7",
    "outputId": "9016b7b9-b035-4f6d-a0c8-8bc7b304c55b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj house : \\n  * xxmaj huberty ( r - xxmaj houston ) , chair \\n  * xxmaj xxunk ( r - xxmaj xxunk ) \\n  * xxmaj bernal ( d - xxmaj san xxmaj antonio ) \\n  * xxmaj gonzalez ( d - xxmaj el xxmaj paso ) \\n  * xxmaj king ( r - xxmaj xxunk ) \\n  xxmaj senate :</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos # xxunk xxmaj baseball xxmaj xxunk : xxmaj april 8th \\n \\n  2 . xxmaj kirbyville xxmaj wildcats \\n  xxmaj record : ( 16 - 6 - 1 ) xxmaj last xxmaj week : # 3 \\n \\n  4 . xxmaj hardin - xxmaj jefferson xxmaj xxunk \\n  xxmaj record : ( 12 - 8 ) xxmaj last xxmaj week : # 8 \\n \\n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos ( xxmaj there were items on it in xxup ut / xxup tt poll : https : / / texaspolitics.utexas.edu / blog / peculiar - partisan - patterns - persist - lukewarm - views - constitutional - revision ¬† ‚Ä¶ ) xxup tx xxmaj senate passes convention of states bills . https : / / www.texastribune.org / 2017 / 02 / 28 / convention - states - legislation -</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj on our way back to xxmaj south xxmaj carolina . xxmaj hope to see you in : \\n  üöô xxmaj bluffton today at 5 ( xxup xxunk xxunk xxmaj middle xxmaj school xxmaj gym ) \\n  üöô xxmaj ladson xxmaj saturday at 9:30 ( xxmaj xxunk 's xxmaj xxunk xxmaj restaurant ) \\n  üöô xxmaj denmark xxmaj saturday at 3 ( xxmaj massachusetts xxmaj hall</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj in one week ! \\n \\n  xxmaj join us , artist xxmaj xxunk , and the xxup sa xxmaj food xxmaj bank ( @safoodbank ) for our xxmaj xxunk xxmaj medal xxmaj food xxmaj drive . xxmaj april 20th . xxup 10am . xxmaj park xxmaj north xxmaj xxunk parking lot . ( xxmaj bring food you would actually eat . xxmaj no cans of xxunk xxunk</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCwf-DyEbVxA"
   },
   "source": [
    "We can then create a model to classify tweets. You can see that in the next two lines we include the processed, hand-coded tweets (`data_clas`), the original Wikitext model (`AWD_LSTM`), and the knowledge we saved after infusing the language model with tweets (`fine_tuned_enc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xlJKU0g3bVxA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3037 items)\n",
       "x: TextList\n",
       "xxbos xxmaj after a couple short - term xxunk , xxmaj kacal has now pushed the bail bill back until tomorrow morning . # txlege,xxbos xxmaj her : xxmaj it ‚Äôs hard for me to open up to someone again . \n",
       " \n",
       "  xxmaj me : xxmaj you can let your guard down , cause i ‚Äôm your guard now !,xxbos xxmaj what does this mean for local taxpayers ? xxmaj local taxpayers will pick up even larger amount of the bill for facilities debt . # txlege # txed,xxbos @scottbraddock xxmaj my view https : / / t.co / xxunk,xxbos xxmaj booming xxmaj oil & & xxmaj gas xxmaj help xxmaj texas xxmaj xxunk xxmaj grow 3 xxmaj times xxmaj faster xxmaj than xxup u.s. xxmaj average https : / / t.co / xxunk # txlege\n",
       "y: CategoryList\n",
       "False,False,False,False,False\n",
       "Path: data;\n",
       "\n",
       "Valid: LabelList (760 items)\n",
       "x: TextList\n",
       "xxbos xxmaj live drawing by xxunk of yesterday 's public hearing on xxup hb xxunk https : / / t.co / xxunk creating a criminal offense for electronic transmission of sexually explicit content -- xxup ceo of @bumble dating app testified # txlege https : / / t.co / xxunk,xxbos xxmaj the xxmaj senate does have a companion bill , so the issue is not entirely dead . xxup sb xxunk is authored by xxmaj sen. xxmaj hughes . # txlege,xxbos xxmaj house now taking up # xxup hjr38 by xxmaj rep @leachfortexas proposing a constitutional amendment prohibiting xxmaj texas from ever xxunk a state income tax . xxmaj thoughts ? # txlege,xxbos xxup hb 2545 - xxmaj relating to the determination of cost of goods sold for purposes of xxunk the franchise tax ... http : / / www.legis.state.tx.us / billlookup / history.aspx?legsess=85r&bill = xxup hb2545 ¬† ‚Ä¶ # txlege,xxbos @lmjread xxunk xxup xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk i had a conflict . i was passing a bill to fund homelessness prevention work in xxmaj dallas at the exact time of the forum . xxmaj sorry i had to miss ; hope it was a good discussion . https : / / t.co / xxunk\n",
       "y: CategoryList\n",
       "False,False,False,False,False\n",
       "Path: data;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(7952, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(7952, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6685884a60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3037 items)\n",
       "x: TextList\n",
       "xxbos xxmaj after a couple short - term xxunk , xxmaj kacal has now pushed the bail bill back until tomorrow morning . # txlege,xxbos xxmaj her : xxmaj it ‚Äôs hard for me to open up to someone again . \n",
       " \n",
       "  xxmaj me : xxmaj you can let your guard down , cause i ‚Äôm your guard now !,xxbos xxmaj what does this mean for local taxpayers ? xxmaj local taxpayers will pick up even larger amount of the bill for facilities debt . # txlege # txed,xxbos @scottbraddock xxmaj my view https : / / t.co / xxunk,xxbos xxmaj booming xxmaj oil & & xxmaj gas xxmaj help xxmaj texas xxmaj xxunk xxmaj grow 3 xxmaj times xxmaj faster xxmaj than xxup u.s. xxmaj average https : / / t.co / xxunk # txlege\n",
       "y: CategoryList\n",
       "False,False,False,False,False\n",
       "Path: data;\n",
       "\n",
       "Valid: LabelList (760 items)\n",
       "x: TextList\n",
       "xxbos xxmaj live drawing by xxunk of yesterday 's public hearing on xxup hb xxunk https : / / t.co / xxunk creating a criminal offense for electronic transmission of sexually explicit content -- xxup ceo of @bumble dating app testified # txlege https : / / t.co / xxunk,xxbos xxmaj the xxmaj senate does have a companion bill , so the issue is not entirely dead . xxup sb xxunk is authored by xxmaj sen. xxmaj hughes . # txlege,xxbos xxmaj house now taking up # xxup hjr38 by xxmaj rep @leachfortexas proposing a constitutional amendment prohibiting xxmaj texas from ever xxunk a state income tax . xxmaj thoughts ? # txlege,xxbos xxup hb 2545 - xxmaj relating to the determination of cost of goods sold for purposes of xxunk the franchise tax ... http : / / www.legis.state.tx.us / billlookup / history.aspx?legsess=85r&bill = xxup hb2545 ¬† ‚Ä¶ # txlege,xxbos @lmjread xxunk xxup xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk xxunk i had a conflict . i was passing a bill to fund homelessness prevention work in xxmaj dallas at the exact time of the forum . xxmaj sorry i had to miss ; hope it was a good discussion . https : / / t.co / xxunk\n",
       "y: CategoryList\n",
       "False,False,False,False,False\n",
       "Path: data;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(7952, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(7952, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6685884a60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(7952, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7952, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(7952, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(7952, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElVQYvpPRwOJ"
   },
   "source": [
    "Again, we need to find the best learning rate, where the slope starts to drop ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qtLBfovqbVxC",
    "outputId": "c9687d87-8db6-47d4-e4ac-fc6f2991243f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "KvESjgILbVxI",
    "outputId": "63ddca80-8175-4f5e-f5df-f74429276416"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Az5OuN6_hJaF"
   },
   "source": [
    "Again, we're using the point where the learning rate slopes down to train our model -- here `1e-2`. We're also using \"momentums\" which we'll get into another time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "S5g2xmtlbVxJ",
    "outputId": "79971cc2-dde2-4dfc-a340-7dcae79f2bdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:05 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.353356</td>\n",
       "      <td>0.229632</td>\n",
       "      <td>0.922368</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBqDZ37oSMkc"
   },
   "source": [
    "Nice accuracy! We can still do more training ... partly because the validation loss is still less than the training loss. Also we freeze the model except the last layer using `freeze_to(-2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "27B3A5PDbVxP",
    "outputId": "40597d91-76eb-4089-9b20-486eff538e64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:06 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.230969</td>\n",
       "      <td>0.206276</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_yMw6DsS_t1"
   },
   "source": [
    "Better! But looks like we can do more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "zQ4AaOVDbVxT",
    "outputId": "fa009202-13c5-47fe-ac56-39a391f04a71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:09 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>0.193025</td>\n",
       "      <td>0.928947</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-uDGwk3THqE"
   },
   "source": [
    "Can we do even better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "4o6ydWNhbVxX",
    "outputId": "798c8d0d-ae1a-4f39-d3e6-580a1c6b54ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:28 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.139325</td>\n",
       "      <td>0.191189</td>\n",
       "      <td>0.932895</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.127208</td>\n",
       "      <td>0.190560</td>\n",
       "      <td>0.935526</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-TSQ7iDTdIG"
   },
   "source": [
    "I'll take 93% accuracy! Let's give it an example ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mBAXEa2MbVxa",
    "outputId": "4163f4ee-f9e0-4d93-b5a2-c47e38a78205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category True, tensor(1), tensor([0.0018, 0.9982]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Four states have two universities represented in the top 20 highest-paid executives of public colleges. Texas has SIX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8u1ptJu1UmT9"
   },
   "source": [
    "`True` means checkable! Let's save our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jykRlEjKU8jS"
   },
   "outputs": [],
   "source": [
    "# optional save, about 300 MB\n",
    "learn.save('pretty_good_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSOgwF1ybVyh"
   },
   "source": [
    "## Preparing for Using Render\n",
    "\n",
    "We could stop here and use this model to guess thousands of saved, unchecked tweets. But I wanted to put this in the wild -- watching for new tweets and sending a Slack message when it spotted a fact-checkable tweet. For that, I hosted the predictor on a service called [Render](https://render.com).\n",
    "\n",
    "My Render code, [which is in this repository](https://github.com/jkeefe/nlp-classifier-fastai-render), needs access to the model and all of its details. So I exported it here, and saved it to a public spot on the internet. \n",
    "\n",
    "The next line (which is optional) will save everything we need for predictions to a ~90MB file to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xxUtm6fMbVxZ"
   },
   "outputs": [],
   "source": [
    "## optional save as `export.pkl`  - about 90 MB\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57uA-44kVh_T"
   },
   "source": [
    "For more about deploying a predictor on Render, see our [blog post about building the checkable-tweets project](https://qz.ai/?p=89)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YsUk3Ypdw2FX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "quartz-fastai-checkable-tweets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
